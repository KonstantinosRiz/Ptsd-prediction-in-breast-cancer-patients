---
title: "Data preprocessing"
output: html_notebook
---

```{r, imports, echo=FALSE, include=FALSE}

library(mice)
library(dplyr)
library(corrplot)
library(caret)
library(purrr)
library(stringr)
library(R.oo)

```

# Data loading and variable renaming

```{r}

# Set the hyperparameters
source("preprocessing_config.R")

setwd(my_path)
load(dataset_path)

# Rename just for ease
data <- dataPCL

# Split the dataset into potential features and potential labels
potential_features <- subset(dataPCL, select = c(mrn : M3_PTGI_appreciation_of_life,
                                       M3_MAC_helpless : Sex_Enjoy_BR23.3))
potential_labels <- subset(dataPCL, select = M6_ptsd_PCL5 : M18_DSMdiagnosis_PCL)

#  Choose my label
label_name <- paste(month_label, "_ptsd_PCL5", sep="")
label <- potential_labels[, label_name]

# Gather the preprocessing comments to have a general idea of what happened
# during every step
preprocessing_comments <- list()

```

# 0. If requested ignore features hinted by medics to have overlapping information

```{r}

if (ignore) {
    features_0 <- potential_features[ , !names(potential_features) %in% ignored_features]
    
    # Comment handling
    comment_0 <- paste("Step 0: Eliminated following features hinted by medics:", paste(ignored_features, collapse=', '), sep='\n')
    preprocessing_comments <- append(preprocessing_comments, comment_0)
  } else {
    features_0 <- potential_features
  }

```

# 1. Eliminate samples with no label

This has to happen before step 2, because I don't wanna count as missing
values of a feature the values of a sample that has no label and is therefore
useless.

```{r}

features_1 <- features_0[!is.na(label), ]
label_1 <- label[!is.na(label)]


# Comment handling
comment_1 <- sprintf("Step 1: Eliminated %i samples with no %s label",
                     nrow(potential_features) - nrow(features_1), label_name)
preprocessing_comments <- append(preprocessing_comments, comment_1)

```

# 2. Eliminate features with too many missing values

```{r}

missing_values_per_column <- colSums(is.na(features_1))
percent_missing_rows <- missing_values_per_column / nrow(features_1)
hist(percent_missing_rows)

feature_selection <- percent_missing_rows <= missing_samples_threshold
features_2 <- features_1[, feature_selection]
label_2 <- label_1


# Comment handling
temp <- names(feature_selection[which(feature_selection == FALSE)])

if (length(temp) != 0) {
  comment_2_1 <- sprintf("Step 2: Eliminated following features with missing values exceeding threshold %.2f", missing_samples_threshold)
  comment_2_2 <- paste(temp, collapse="\n")
  comment_2 <- paste(comment_2_1, comment_2_2, sep="\n")
} else {
  comment_2 <- sprintf("Step 2: No features had enough missing values to be eliminated using threshold %.2f", missing_samples_threshold)
}
preprocessing_comments <- append(preprocessing_comments, comment_2)

```

# 3. Eliminate samples with too many missing values

```{r}

missing_values_per_row <- rowSums(is.na(features_2))

percent_missing_cols <- missing_values_per_row / ncol(features_1)
hist(percent_missing_cols)

sample_selection <- percent_missing_cols <= missing_features_threshold
features_3 <- features_2[sample_selection, ]
final_label <- label_2[sample_selection]


# Comment handling
temp <- data[names(sample_selection[which(sample_selection == FALSE)]), ]$mrn

if (length(temp) != 0) {
  comment_3_1 <- sprintf("Step 3: Eliminated following samples with missing values exceeding threshold %f", missing_features_threshold)
  comment_3_2 <- paste(temp, collapse=", ")
  comment_3 <- paste(comment_3_1, comment_3_2, sep="\n")
} else {
  comment_3 <- sprintf("Step 2: No samples had enough missing values to be eliminated using threshold %i missing features", missing_features_threshold)
}
preprocessing_comments <- append(preprocessing_comments, comment_3)

```

# 4. Eliminate discrete features with near zero variance

```{r}

near_zero_var_indices <- nearZeroVar(features_3, freqCut=freqCut, uniqueCut=uniqueCut)
if (identical(near_zero_var_indices, integer(0))) {
  features_4 <- features_3
} else {
  features_4 <- features_3[, -near_zero_var_indices]
}


# Comment handling
if (length(near_zero_var_indices) != 0) {
  near_zero_var_names <- colnames(features_3)[near_zero_var_indices]
  comment_4 <- paste("Step 4: Eliminated following features with near zero variance:", paste(near_zero_var_names, collapse=', '), sep='\n')
} else {
  comment_4 <- "Step 4: No features were eliminated due to having near zero variance"
}
preprocessing_comments <- append(preprocessing_comments, comment_4)

```

# 5. Eliminate highly correlated features

```{r}

# Use only numeric features
numeric_features <- features_4 %>% select_if(is.numeric)
correlation <- cor(numeric_features, method=c(correlation_method), use = "pairwise.complete.obs")

# Find which features need to be eliminated due to high correlation with others
correlation[!lower.tri(correlation)] <- 0
numeric_features_selection <- apply(correlation, 1,
                                    function(row) any(abs(row) > 0.8, na.rm = TRUE))
highly_correlated_numeric_features <- numeric_features_selection[which(numeric_features_selection == TRUE)]
# Find the indices of these features
highly_correlated_indices <- map_int( names(highly_correlated_numeric_features), grep, names(features_4) )

if (identical(highly_correlated_indices, integer(0))) {
  features_5 <- features_4
} else {
  features_5 <- features_4[, -highly_correlated_indices]
}


# Comment handling
if (length(highly_correlated_indices) != 0) {
  # We find which features the ones we delete correlate with
  temp_comments <- c()
  for (j in names(highly_correlated_numeric_features)) {
    corr_row <- correlation[j, ]
    correlated_features <- names(corr_row[abs(corr_row) > cor_threshold])
    my_comment <- sprintf("%s is highly correlated with %s", j, correlated_features[1])
    temp_comments <- union(temp_comments, my_comment)
  }
  
  comment_5 <- paste("Step 5: Eliminated following features with high correlation:", paste(temp_comments, collapse='\n'), sep='\n')
} else {
  comment_5 <- "Step 5: No features were eliminated due to having high correlation with another"
}
preprocessing_comments <- append(preprocessing_comments, comment_5)

```

# 6. Split the dataset into train/test

```{r}

# Threshold the label
new_final_label <- as.factor(as.integer(final_label >= ptsd_threshold))

if (split_method == 'random') {
  train_indices <- createDataPartition(new_final_label, p=train_size, list=FALSE)
  
  # Comment handling
  comment_6 <- sprintf("Step 6: Split the dataset into train/test randomly with a %.2f ratio", train_size)
} else {
  hospitals <- as.character(features_5$mrn)
  
  IEO_indices <- which(str_detect(hospitals, "EIEO"))
  HUS_indices <- which(str_detect(hospitals, "HUS"))
  rabin_indices <- which(str_detect(hospitals, "Rabin Medical Center"))
  shaare_zedek_indices <- which(str_detect(hospitals, "shaare zedek"))
  HUJI_indices <- union(rabin_indices, shaare_zedek_indices)
  
  all_indices <- c(1:nrow(features_5))
  to_exclude_indices <- union(IEO_indices, HUS_indices)
  to_exclude_indices <- union(to_exclude_indices, HUJI_indices)
  CHA_indices <- all_indices[-to_exclude_indices]
  
  if (split_method == "IEO") {
    train_indices <- union(HUS_indices, HUJI_indices)
    train_indices <- union(train_indices, CHA_indices)
  } else if (split_method == "HUS") {
    train_indices <- union(IEO_indices, HUJI_indices)
    train_indices <- union(train_indices, CHA_indices)
  } else if (split_method == "HUJI") {
    train_indices <- union(IEO_indices, HUS_indices)
    train_indices <- union(train_indices, CHA_indices)
  } else if (split_method == "CHA") {
    # CHA case
    train_indices <- union(IEO_indices, HUS_indices)
    train_indices <- union(train_indices, HUJI_indices)
  } else {
    throw("Split method is not one of the allowed. Use one of ['random', 'IEO', 'HUS', 'HUJI', 'CHA']")
  }
  
  # Comment handling
  comment_6 <- paste("Step 6: Split the dataset into train/test using as test set the data from", split_method)
  
}

features_6 <- subset(features_5, select = -c(mrn))
# Drop unused factor levels
# features_6 <- droplevels(features_6)

preprocessing_comments <- append(preprocessing_comments, comment_6)

```

# 7. Impute missing values

```{r}

# I impute using only the train samples but apply the imputation process to the test set as well.
ignore_vector <- rep(TRUE, nrow(features_6))
ignore_vector[train_indices] <- FALSE

imp_data <- mice(features_6, m=number_of_imputed_datasets, method=imputation_method, ignore=ignore_vector)

final_features = list()
for (i in 1 : number_of_imputed_datasets) {
  final_features[[i]] <- complete(imp_data, i)
}

# Comment handling
comment_7 <- sprintf("Step 7: Used Multiple Imputation Chained Equations (MICE) to impute %i different datasets", number_of_imputed_datasets)
preprocessing_comments <- append(preprocessing_comments, comment_7)

```

We plan to use all the different imputed datasets to predict using our model and
afterwards average the results. The idea is that each imputed dataset is an approach
of the "real" dataset (many values of which are unknown) and using all the approaches
will get us to a more realistic result


# Final save file which will be used to train and evaluate the models

```{r}

setwd("D:/Κωνσταντίνος Data/Σχολής/Διπλωματική Εργασία/Main/dataset/preprocessed_results")

if (val_size != 0) {
  # Create the validation set indices
  val_indices <- createDataPartition(new_final_label[train_indices], p=val_size, list=FALSE)
  
  save(final_features, new_final_label, train_indices, val_indices, preprocessing_comments, config_list, file=save_file_name)
} else {
  save(final_features, new_final_label, train_indices, preprocessing_comments, config_list, file=save_file_name)
}

setwd("D:/Κωνσταντίνος Data/Σχολής/Διπλωματική Εργασία/Main/source")

```
