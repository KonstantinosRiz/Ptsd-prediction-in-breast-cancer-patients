---
title: "Model development"
output: html_notebook
---

```{r, imports, echo=FALSE, include=FALSE}
# library(smotefamily)
library(plyr)
library(dplyr)
library(ROSE)
library(rpart)
library(rpart.plot)
library(tidyverse)
library(ModelMetrics)
library(caret)
library(themis)
library(ranger)
library(randomForest)
library(mice)
library(sos)
library(kernlab)
library(ramify)
library(Matrix)
library(MLmetrics)
library(pROC)
library(hash)
library(numbers)
library(ggplot2)
library(e1071)
```

Initializing and loading the preprocessed, clean dataset which includes:

1. final_features:            list of m datasets created during preprocessing (containing only the features)
2. new_final_label:           the labels (same for all the datasets)
3. train_indices:             the indices of the samples that belong to the train set
4. preprocessing_comments:    detailed comments about the preprocessing procedure
5. config_list:               named list containing the parameters used to preprocess the dataset

```{r, load_data, echo=TRUE}

# Absolute path
my_path <- r"{D:\Κωνσταντίνος Data\Σχολής\Διπλωματική Εργασία\Main\source}"
setwd(my_path)

# Relative path
clean_data_folder <- r"{..\dataset\preprocessed_results}"
data_file <- r"{\M6_random_ignored.RData}"
data_path <- paste(clean_data_folder, data_file, sep="")

load(data_path)

# Print the preprocessing comments
cat(paste(preprocessing_comments, collapse="\n\n"))

```

```{r, load_code, echo=TRUE}

source("models_config.R")
source("models_aux.R")

```

```{r, split, echo=TRUE}

# Find the optimal model for every imputed dataset
# for (i in 1:as.integer(config_list["number_of_imputed_datasets"]) {

data <- final_features[[1]]

# Split the dataset into train/test (technically the split has happened during the preprocessing,
# we are just grouping together)
train_features <- data[train_indices, ]
test_features <- data[-train_indices, ]

train_labels <- new_final_label[train_indices]
test_labels <- new_final_label[-train_indices]

# One-hot-encode our features for the models that can't handle factors
dummy <- dummyVars("~.", data = data)
one_hot_train_features <- data.frame(predict(dummy, newdata = train_features))
one_hot_test_features <- data.frame(predict(dummy, newdata = test_features))

```

# Feature reduction using RFE

```{r, rfe, echo=TRUE}

myFuncs <- rfFuncs
myFuncs$summary <- many_stats_summary
myFuncs$selectSize <- myPickSizeTolerance
if (rfe_sampling_method == "down") {
  myFuncs$fit <- rf_fit_down
}
rfe_control <- rfeControl(
  functions = myFuncs,
  method = "repeatedcv",
  number = rfe_k_fold,
  repeats = rfe_repeats,
  verbose = FALSE,
  returnResamp = "all"
)

## Rfe on initial features

rfe <- rfe(
  train_features, train_labels,
  sizes = rfe_sizes,
  rfeControl = rfe_control,
  metric = metric,
  ntree = rfe_trees
)
cat(paste(sprintf("RFE decided that the optimal number of features is %i:", rfe$optsize), paste(rfe$optVariables, collapse=", "), sep="\n"))
cat('\n\n')
  
train_reduced <- train_features[, rfe$optVariables]
test_reduced <- test_features[, rfe$optVariables]

## Rfe on one-hot encoded features

rfe_one_hot <- rfe(
  one_hot_train_features, train_labels, 
  sizes = rfe_sizes,
  rfeControl = rfe_control,
  metric = metric,
  ntree = rfe_trees
)
cat(paste(sprintf("RFE decided that the optimal number of one-hot encoded features is %i:", rfe_one_hot$optsize), paste(rfe_one_hot$optVariables, collapse=", "), sep="\n"))

one_hot_train_reduced <- one_hot_train_features[, rfe_one_hot$optVariables]
one_hot_test_reduced <- one_hot_test_features[, rfe_one_hot$optVariables]

```

# Models

Run the wanted model using all the combinations of the hyperparameters in the respective grid, find the optimal model and evaluate it on the test set. We try the full-featured dataset where there are no limitations by the model. We try the one-hot encoded dataset where we can't use factors.

```{r, train_control, echo=TRUE}

# Use repeated k-fold cross validation to evaluate the models
# and the appropriate summary function for the metric (f2/auc)
ctrl <- trainControl(
  method = "repeatedcv",
  number = k_fold,
  repeats = repeats,
  summaryFunction = f2_summary,
  sampling = sampling_method,
  verboseIter = FALSE
)

```

## Decision Tree

```{r, dt, echo=TRUE}

gs <- data.frame(cp = c(0.001, 0.005, 0.01, 0.05, 0.1))

# All features
dt <- run_model(gs, train_features, train_labels, test_features, test_labels, method="rpart", ctrl)

# Reduced features
dt_reduced <- run_model(gs, train_reduced, train_labels, test_reduced, test_labels, method="rpart", ctrl)

```

## Random Forest

```{r, rf, echo=TRUE}

default <- round(sqrt(ncol(train_features)))
gs <- data.frame(mtry = c(default - 10, default - 5, default, default + 5, default + 10, default + 20))

# All features
rf <- run_model(gs, train_features, train_labels, test_features, test_labels, method="rf", ctrl)

# Appropriate upper limit
default <- round(sqrt(ncol(train_reduced)))
gs <- data.frame(mtry = c(default, default + 2, default + 4, default + 6))

# Reduced features
rf_reduced <- run_model(gs, train_reduced, train_labels, test_reduced, test_labels, method="rf", ctrl)

```

## Support vector machines

```{r, SVM, echo=TRUE}

# One-hot encoded features
gs <- expand.grid(C = c(1),
                  sigma = c(1 / ncol(one_hot_train_features)),
                  Weight = seq(0.5, 2, by=0.5))

svm <- run_model(gs, one_hot_train_features, train_labels, one_hot_test_features, test_labels, method="svmRadialWeights", ctrl)

# One-hot reduced features
gs <- expand.grid(C = c(1),
                  sigma = c(1 / ncol(one_hot_train_reduced)),
                  Weight = seq(0.5, 2, by=0.5))

svm_reduced <- run_model(gs, one_hot_train_reduced, train_labels, one_hot_test_reduced, test_labels, method="svmRadialWeights", ctrl)


```

## Adaboost

```{r, adaboost, echo=TRUE}

gs <- expand.grid(mfinal = c(10, 20, 50, 100, 150),
                  maxdepth = c(1, 2),
                  coeflearn = c("Breiman"))

# All features
adaboost <- run_model(gs, train_features, train_labels, test_features, test_labels, method="AdaBoost.M1", ctrl)

# All features reduced
adaboost_reduced <- run_model(gs, train_reduced, train_labels, test_reduced, test_labels, method="AdaBoost.M1", ctrl)

```

## Gradient boost

```{r, gradient_boost, echo=TRUE}

gs <- expand.grid(nrounds = c(10, 20, 50, 100),
                  max_depth = 6,
                  eta = 0.3,
                  gamma = 0,
                  colsample_bytree = 1,
                  min_child_weight = 1,
                  subsample = 1
                  )

# One_hot features
xgboost <- run_model(gs, one_hot_train_features, train_labels, one_hot_test_features, test_labels, method="xgbTree", ctrl)

# One_hot reduced features
xgboost_reduced <- run_model(gs, one_hot_train_reduced, train_labels, one_hot_test_reduced, test_labels, method="xgbTree", ctrl)

```
## Voting classifier

```{r, voting_classifier, echo=TRUE}

## Using all features
voting <- voting_classifier(dt, rf, svm, adaboost, xgboost)

## Using reduced features
voting_reduced <- voting_classifier(dt_reduced, rf_reduced, svm_reduced, adaboost_reduced, xgboost_reduced)

```

```{r, grouped_results}

# Using all the features
auc_scores <- c(dt$auc, rf$auc, svm$auc, adaboost$auc, xgboost$auc, voting$auc)
f2_scores <- c(dt$f2, rf$f2, svm$f2, adaboost$f2, xgboost$f2, voting$f2)
visualization_results <- visualize(auc_scores, f2_scores, 'Performance using all features')

# Using reduced features
auc_scores_reduced <- c(dt_reduced$auc, rf_reduced$auc, svm_reduced$auc, adaboost_reduced$auc, xgboost_reduced$auc, voting_reduced$auc)
f2_scores_reduced <- c(dt_reduced$f2, rf_reduced$f2, svm_reduced$f2, adaboost_reduced$f2, xgboost_reduced$f2, voting_reduced$f2)
visualization_results_reduced <- visualize(auc_scores_reduced, f2_scores_reduced, 'Performance using reduced features')

```
